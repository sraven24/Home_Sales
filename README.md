# Home_Sales

In this challenge, Pyspark was used to run queries on a home sales data frame.  Techniques such as caching data and partitioning were used to improve the performance of the queries.  

# Installation

Run the ipynb folder from Google Colab to execute the code.  Please make sure that you have the current version of Pyspark, which is 3.4.0, installed on your system in order to run the code.  If you do not have that version, you can change the line "spark version" to what is currently installed in your system. 

# Resources

Most of the information for this challenge was from the activities in the module for week 22.  However, https://spark.apache.org/docs/latest/api/python/getting_started/install.html was needed to troubleshoot issues with the Pyspark versions not working.
